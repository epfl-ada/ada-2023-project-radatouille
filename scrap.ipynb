{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match IMDB, MetaCritic and Freebase IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IDS(imdb_ids=[], freebase_ids=[]):\n",
    "    '''\n",
    "        Get the imdb_id, freebase_id and metacritic_id from the wikidata database\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        imdb_ids : str\n",
    "            The imdb id of the movie\n",
    "        freebase_id : str\n",
    "            The freebase id of the movie\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        imdb_id : str\n",
    "            The imdb id of the movie\n",
    "        freebase_id : str\n",
    "            The freebase id of the movie\n",
    "        metacritic_id : str\n",
    "            The metacritic id of the movie\n",
    "    '''\n",
    "    if len(imdb_ids) > 0:\n",
    "        imdb_ids_string = \" \".join(f'\"{id_}\"' for id_ in imdb_ids)\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT ?item ?freebaseId ?metacriticId ?imdbId WHERE {{\n",
    "            VALUES ?imdbId {{ {imdb_ids_string} }}\n",
    "            ?item wdt:P345 ?imdbId .\n",
    "            OPTIONAL {{ ?item wdt:P646 ?freebaseId }}\n",
    "            OPTIONAL {{ ?item wdt:P1712 ?metacriticId }}\n",
    "            }}\n",
    "        \"\"\"\n",
    "\n",
    "    elif len(freebase_ids) > 0:\n",
    "        freebase_ids_string = \" \".join(f'\"{id_}\"' for id_ in freebase_ids)\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT ?item ?freebaseId ?metacriticId ?imdbId WHERE {{\n",
    "            VALUES ?freebaseId {{ {freebase_ids_string} }}\n",
    "            ?item wdt:P646 ?freebaseId .\n",
    "            OPTIONAL {{ ?item wdt:P1712 ?metacriticId }}\n",
    "            OPTIONAL {{ ?item wdt:P345 ?imdbId }}\n",
    "            }}\n",
    "        \"\"\"\n",
    "\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) \\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    encoded_query = urllib.parse.quote(query)\n",
    "    query_url = f\"https://query.wikidata.org/bigdata/namespace/wdq/sparql?format=json&query={encoded_query}\"\n",
    "\n",
    "    response = requests.get(query_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return None, None, None\n",
    "    \n",
    "    data = response.json()\n",
    "\n",
    "    if len(data[\"results\"][\"bindings\"]) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    data = data[\"results\"][\"bindings\"]\n",
    "    \n",
    "    imdb_ids = []\n",
    "    freebase_ids = []\n",
    "    metacritic_ids = []\n",
    "\n",
    "    for item in data:\n",
    "        if \"freebaseId\" in item:\n",
    "            freebase_ids.append(item[\"freebaseId\"][\"value\"])\n",
    "        else:\n",
    "            freebase_ids.append(None)\n",
    "        \n",
    "        if \"metacriticId\" in item:\n",
    "            metacritic_ids.append(item[\"metacriticId\"][\"value\"])\n",
    "        else:\n",
    "            metacritic_ids.append(None)\n",
    "\n",
    "        if \"imdbId\" in item:\n",
    "            imdb_ids.append(item[\"imdbId\"][\"value\"])\n",
    "        else:\n",
    "            imdb_ids.append(None)\n",
    "\n",
    "    return imdb_ids, freebase_ids, metacritic_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_imdb_and_metacritics_ids(movies, batch_size=100):\n",
    "\n",
    "    new_movies = movies.copy()\n",
    "\n",
    "    # Initializing imdb_id and metacritic_id columns if they don't exist\n",
    "    if 'imdb_id' not in new_movies.columns:\n",
    "        new_movies['imdb_id'] = None\n",
    "    if 'metacritic_id' not in new_movies.columns:\n",
    "        new_movies['metacritic_id'] = None\n",
    "\n",
    "    for i in tqdm(range(0, len(new_movies), batch_size)):\n",
    "        batch = new_movies.iloc[i:i+batch_size]\n",
    "\n",
    "        # drop columns imdb_id and metacritic_id\n",
    "        batch = batch.drop(columns=[\"imdb_id\", \"metacritic_id\"])\n",
    "\n",
    "        imdb_ids, freebase_ids, metacritic_ids = get_IDS(freebase_ids=batch[\"freebase_id\"].values)\n",
    "\n",
    "        ids_mapping = pd.DataFrame({\"freebase_id\": freebase_ids, \"imdb_id\": imdb_ids, \"metacritic_id\": metacritic_ids})\n",
    "\n",
    "        # if duplicates then set imdb and metacritic ids to None\n",
    "        duplicates = ids_mapping[\"freebase_id\"].duplicated(keep=False)\n",
    "        ids_mapping.loc[duplicates, [\"imdb_id\", \"metacritic_id\"]] = None\n",
    "\n",
    "        # removing duplicates\n",
    "        ids_mapping = ids_mapping.drop_duplicates(subset=[\"freebase_id\"])\n",
    "\n",
    "        # Ensuring one-to-one correspondence\n",
    "        if not ids_mapping[\"freebase_id\"].is_unique:\n",
    "            # print duplicates\n",
    "            raise ValueError(\"Duplicate freebase_ids found in ids_mapping.\")\n",
    "\n",
    "        # Merging and updating the DataFrame\n",
    "        batch_updated = batch.merge(ids_mapping, on=\"freebase_id\", how=\"left\")\n",
    "        new_movies.iloc[i:i+batch_size] = batch_updated\n",
    "\n",
    "    return new_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/preprocessed/movie.metadata.preprocessed.tsv', sep='\\t')\n",
    "\n",
    "cmu_movies = add_imdb_and_metacritics_ids(movies, batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_movies.to_csv('data/processed/cmu_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metacritic Critics Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_metacritics_movie(metacriticID):\n",
    "\n",
    "    url = f\"https://www.metacritic.com/{metacriticID}/critic-reviews\"\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) \\\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    script_tag = soup.find('script', string=lambda t: t and 'window.__NUXT__' in t)\n",
    "\n",
    "    # Define a regular expression pattern to match objects with specific attributes\n",
    "    pattern = r\"\\{[^{}]*reviewedProduct:\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}[^{}]*\\}\"\n",
    "\n",
    "    if not script_tag:\n",
    "        return None\n",
    "    \n",
    "    # Find all matches of the pattern in the input text\n",
    "    matches = re.findall(pattern, script_tag.text, re.DOTALL)\n",
    "    \n",
    "    def extract_info(data_string):\n",
    "        \n",
    "        # Regular expressions for score (next to metaScore), author, and publicationName\n",
    "        metascore_pattern = r\"criticScoreSummary:\\{[^\\}]*score:(\\d+)\"\n",
    "        score_pattern = r'score:([a-zA-Z]|\\d+),\\s*metaScore'\n",
    "        author_pattern = r'author:\"([^\"]+)\"'\n",
    "        publication_name_pattern = r'publicationName:\"([^\"]+)\"'\n",
    "\n",
    "        # Extracting score\n",
    "        score_match = re.search(score_pattern, data_string)\n",
    "        if score_match:\n",
    "            score = score_match.group(1)\n",
    "            if score.isalpha():\n",
    "                score = 0\n",
    "            else:\n",
    "                score = int(score)\n",
    "        else:\n",
    "            score = None\n",
    "\n",
    "        # Extracting author\n",
    "        author_match = re.search(author_pattern, data_string)\n",
    "        author = author_match.group(1) if author_match else None\n",
    "\n",
    "        # Extracting publicationName\n",
    "        publication_name_match = re.search(publication_name_pattern, data_string)\n",
    "        publication_name = publication_name_match.group(1) if publication_name_match else None\n",
    "\n",
    "        # Extracting metascore\n",
    "        metascore_match = re.search(metascore_pattern, data_string)\n",
    "        metascore = metascore_match.group(1) if metascore_match else None\n",
    "\n",
    "        return score, author, publication_name, metascore\n",
    "        \n",
    "    reviews_data = {\"publisher\": [], \"author\": [], \"metacritic_rating\": [], \"metascore\": []}\n",
    "    \n",
    "    for review in matches:\n",
    "\n",
    "        score, author, publisher, metascore = extract_info(review)\n",
    "\n",
    "        reviews_data[\"publisher\"].append(publisher)\n",
    "        reviews_data[\"author\"].append(author)\n",
    "        reviews_data[\"metacritic_rating\"].append(score)\n",
    "        reviews_data[\"metascore\"].append(metascore)\n",
    "\n",
    "    reviews_df = pd.DataFrame(reviews_data)\n",
    "\n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_metacritics(movies_df, save_step=250, filepath=\"data/external/metacritic_reviews.csv\"):\n",
    "    if not os.path.exists(\"data/scrap/metacritic_reviews.csv\"):\n",
    "        metacritic_reviews = pd.DataFrame(columns=[\"publisher\", \"author\", \"metacritic_rating\", \"metascore\", \"metacritic_id\"])\n",
    "    else:\n",
    "        metacritic_reviews = pd.read_csv(\"data/scrap/metacritic_reviews.csv\")\n",
    "\n",
    "    already_scraped_movies_ids = metacritic_reviews[\"metacritic_id\"].unique()\n",
    "\n",
    "    # filter movies that have already been scraped\n",
    "    \n",
    "    movies_df = movies_df.loc[~movies_df[\"metacritic_id\"].isin(already_scraped_movies_ids)]\n",
    "\n",
    "    movies_df = movies_df.loc[movies_df[\"metacritic_id\"].notna()]\n",
    "\n",
    "    initial_len = len(metacritic_reviews)\n",
    "\n",
    "    for i, row in tqdm(movies_df.iterrows(), total=len(movies_df)):\n",
    "        metacritic_id = row[\"metacritic_id\"]\n",
    "\n",
    "        if not metacritic_id:\n",
    "            continue\n",
    "\n",
    "        reviews = scrap_metacritics_movie(metacritic_id)\n",
    "\n",
    "        if reviews is None:\n",
    "            continue\n",
    "\n",
    "        reviews[\"metacritic_id\"] = row[\"metacritic_id\"]\n",
    "\n",
    "        metacritic_reviews = pd.concat([metacritic_reviews, reviews], ignore_index=True)\n",
    "\n",
    "        if i % save_step == 0:\n",
    "            metacritic_reviews.to_csv(\"data/scrap/metacritic_reviews.csv\", index=False)\n",
    "            print(\"Saved {} new reviews\".format(len(metacritic_reviews) - initial_len))\n",
    "            initial_len = len(metacritic_reviews)\n",
    "\n",
    "    metacritic_reviews.to_csv(filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"data/processed/cmu_movies.csv\")\n",
    "\n",
    "scrap_metacritics(movies, save_step=250, filepath=\"data/external/metacritic_reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
